{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "This file demonstrate how to use GAN Generator/Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator/Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=64, image_size=28):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.image_size = image_size\n",
    "        self.output_dim = 1 * image_size * image_size  # same as origin image\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.output_dim),\n",
    "            nn.BatchNorm1d(self.output_dim),\n",
    "            nn.Tanh(), # ~[-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, self.output_dim)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_size=28):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = 1 * image_size * image_size\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.fc(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data -> Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def loading_data(input_size=28, batch_size=128):\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                    transforms.Grayscale(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.5,), std=(0.5,)) # [0, 1] -> [-1, 1]\n",
    "    ])\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        datasets.MNIST(\"../data/mnist\", train=True, download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(image_size=IMAGE_SIZE)\n",
    "generator = Generator(image_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossF = nn.BCELoss()\n",
    "lrG = 0.0002\n",
    "lrD = 0.0002\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lrG)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lrD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(generator, discriminator, optimizer, real_data, batch_size, z_size):\n",
    "    # Reshape real_data to vector\n",
    "    real_data = real_data.view(batch_size, -1)\n",
    "    # Rescale real_data to range -1 - 1\n",
    "    real_data = scale(real_data)\n",
    "    \n",
    "    # Reset gradients and set model to training mode\n",
    "    optimizer.zero_grad()\n",
    "    discriminator.train()\n",
    "    \n",
    "    # Train on real data\n",
    "    real_data_logits = discriminator.forward(real_data)\n",
    "    loss_real = real_loss(real_data_logits, smooth=True)\n",
    "    # Generate fake data\n",
    "    z_vec = random_vector(batch_size, z_size)\n",
    "    fake_data = generator.forward(z_vec)\n",
    "    # Train on fake data\n",
    "    fake_data_logits = discriminator.forward(fake_data)\n",
    "    loss_fake = fake_loss(fake_data_logits)\n",
    "    # Calculate total loss\n",
    "    total_loss = loss_real + loss_fake\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def train_generator(generator, discriminator, optimizer, batch_size, z_size):\n",
    "    # Reset gradients and set model to training mode\n",
    "    optimizer.zero_grad()\n",
    "    generator.train()\n",
    "    # Generate fake data\n",
    "    z_vec = random_vector(batch_size, z_size)\n",
    "    fake_data = generator.forward(z_vec)\n",
    "    # Train generator with output of discriminator\n",
    "    discriminator_logits = discriminator.forward(fake_data)\n",
    "    # Reverse labels\n",
    "    loss = real_loss(discriminator_logits)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(predictions, smooth=False):\n",
    "    batch_size = predictions.shape[0]\n",
    "    labels = torch.ones(batch_size)\n",
    "    # Smooth labels for discriminator to weaken learning\n",
    "    if smooth:\n",
    "        labels = labels * 0.9\n",
    "    # We use the binary cross entropy loss | Model has a sigmoid function\n",
    "    criterion = nn.BCELoss()\n",
    "    # Move models to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    loss = criterion(predictions.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(predictions):\n",
    "    batch_size = predictions.shape[0]\n",
    "    labels = torch.zeros(batch_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    # Move models to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        labels = labels.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    loss = criterion(predictions.squeeze(), labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 50\n",
    "IMAGE_SIZE = 28\n",
    "BATCH_SIZE = 128\n",
    "SAMPLE_SIZE = 8 # Show numbers of image\n",
    "PLOT_EVERY = 5  # plot every epoch\n",
    "Z_INDEX = 100\n",
    "\n",
    "sample_noise = Variable(torch.randn(BATCH_SIZE, Z_INDEX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-401496b692a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "data_loader = loading_data(input_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "for e in range(EPOCHES):\n",
    "    for n, (images, _) in enumerate(data_loader):\n",
    "        assert (images.shape[0] == BATCH_SIZE)\n",
    "        \n",
    "        d_loss = \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
